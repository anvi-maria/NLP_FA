{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d1488-feb1-43d9-8c8f-3430ce9492c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Download NLTK resources if not already installed\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fb0102-dd84-4f33-baa8-cfc614b83a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded:\n",
      "                                             Comment Emotion\n",
      "0  i seriously hate one subject to death but now ...    fear\n",
      "1                 im so full of life i feel appalled   anger\n",
      "2  i sit here to write i start to dig out my feel...    fear\n",
      "3  ive been really angry with r and i feel like a...     joy\n",
      "4  i feel suspicious if there is no one outside l...    fear\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\anvim\\Desktop\\PYTHON ASS\\machine learning\\nlp_dataset.csv\"\n",
    "data = pd.read_csv(file_path)  # Replace with the correct file extension if not .csv\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(\"Dataset Loaded:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check if required columns are present\n",
    "if 'Comment' not in data.columns or 'Emotion' not in data.columns:\n",
    "    raise ValueError(\"Dataset must contain 'Comment' and 'Emotion' columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce99599f-5fc9-4879-80b8-0b86bbaf59a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.5 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/41.5 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/41.5 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/41.5 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/41.5 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 111.4 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 51.2/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 51.2/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 51.2/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 51.2/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 189.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.5/1.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.4/1.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 174.1/273.6 kB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 266.2/273.6 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 273.6/273.6 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 92.2/97.9 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.9/97.9 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.5 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.5/78.5 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091b5300-f63c-4ddf-a2fc-72aba169877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0f66ff-fde8-4a75-84a8-bb88160e646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anvim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05125981-d185-4a5b-9b73-417abd094d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Text Cleaning\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove special characters, punctuation, and convert text to lowercase.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation and special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "data['cleaned_comment'] = data['Comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c33467-50e9-4a04-93f6-38e4d239c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded:\n",
      "                                             Comment Emotion  \\\n",
      "0  i seriously hate one subject to death but now ...    fear   \n",
      "1                 im so full of life i feel appalled   anger   \n",
      "2  i sit here to write i start to dig out my feel...    fear   \n",
      "3  ive been really angry with r and i feel like a...     joy   \n",
      "4  i feel suspicious if there is no one outside l...    fear   \n",
      "\n",
      "                                     cleaned_comment  \n",
      "0  i seriously hate one subject to death but now ...  \n",
      "1                 im so full of life i feel appalled  \n",
      "2  i sit here to write i start to dig out my feel...  \n",
      "3  ive been really angry with r and i feel like a...  \n",
      "4  i feel suspicious if there is no one outside l...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Loaded:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1df0ef1b-7019-41ca-9f52-f5651d1561ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18ddbcdf-73ba-44f3-9410-796ecfbc81f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.2-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.11-cp312-cp312-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.10-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.2-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.32.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "     ---------------------------------------- 0.0/169.7 kB ? eta -:--:--\n",
      "     ------------------------------------ - 163.8/169.7 kB 4.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 169.7/169.7 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Collecting setuptools (from spacy)\n",
      "  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (24.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.0)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.0.1-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.2-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.8 MB 4.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/11.8 MB 8.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/11.8 MB 6.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/11.8 MB 7.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/11.8 MB 8.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.5/11.8 MB 9.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/11.8 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.6/11.8 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.3/11.8 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.6/11.8 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/11.8 MB 9.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.8 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.7/11.8 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.8/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/11.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.1/11.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.8 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.7/11.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/11.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.8/11.8 MB 8.6 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.10-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/183.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 183.0/183.0 kB 11.5 MB/s eta 0:00:00\n",
      "Downloading murmurhash-1.0.11-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.4/122.4 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "   ---------------------------------------- 0.0/455.3 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 317.4/455.3 kB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.3/455.3 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.27.1-cp312-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 8.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.0 MB 7.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.5 MB/s eta 0:00:00\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-win_amd64.whl (478 kB)\n",
      "   ---------------------------------------- 0.0/478.8 kB ? eta -:--:--\n",
      "   ----------------------------------- --- 430.1/478.8 kB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 478.8/478.8 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading thinc-8.3.2-cp312-cp312-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.7/44.7 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.3/50.3 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.4/1.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.7/1.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-1.0.1-cp312-cp312-win_amd64.whl (6.4 MB)\n",
      "   ---------------------------------------- 0.0/6.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.7/6.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.1/6.4 MB 8.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.5/6.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.9/6.4 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.3/6.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.7/6.4 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.1/6.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.5/6.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.0/6.4 MB 8.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.4/6.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.4 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.2/6.4 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.3/6.4 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.3/6.4 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.4/6.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.4/6.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.4/6.4 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "   ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.6/5.4 MB 7.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.0/5.4 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.4/5.4 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.8/5.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.3/5.4 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.7/5.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.1/5.4 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.5/5.4 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.0/5.4 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.7/5.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.4/5.4 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 242.4/242.4 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.4/61.4 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 150.8/150.8 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.17.0-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, typing-extensions, spacy-loggers, spacy-legacy, shellingham, setuptools, murmurhash, mdurl, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic-core, preshed, markdown-it-py, marisa-trie, rich, pydantic, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-1.0.1 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.10 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.11 preshed-3.0.9 pydantic-2.10.1 pydantic-core-2.27.1 rich-13.9.4 setuptools-75.6.0 shellingham-1.5.4 smart-open-7.0.5 spacy-3.8.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.3.2 typer-0.13.1 typing-extensions-4.12.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669f227-f8ad-4d7f-b5f0-9fda1d6c99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['cleaned_comment'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907a303-dda8-4c15-8c8c-b39f956516bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Remove common stopwords from tokenized text.\n",
    "    \"\"\"\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "data['tokens_no_stopwords'] = data['tokens'].apply(remove_stopwords)\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(\"Preprocessed Data:\")\n",
    "print(data[['comment', 'emotion', 'cleaned_comment', 'tokens_no_stopwords']].head())\n",
    "\n",
    "# Save the processed data to a new file if needed\n",
    "processed_file_path = r\"C:\\Users\\anvim\\Desktop\\PYTHON ASS\\machine learning\\nlp_dataset_processed.csv\"\n",
    "data.to_csv(processed_file_path, index=False)\n",
    "print(f\"Processed data saved to: {processed_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245904fd-3f18-4a80-b6fb-c5e1873690ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 108.9 kB/s eta 0:01:58\n",
      "     --------------------------------------- 0.0/12.8 MB 145.2 kB/s eta 0:01:28\n",
      "     --------------------------------------- 0.1/12.8 MB 201.8 kB/s eta 0:01:04\n",
      "     --------------------------------------- 0.1/12.8 MB 245.8 kB/s eta 0:00:52\n",
      "     --------------------------------------- 0.1/12.8 MB 400.9 kB/s eta 0:00:32\n",
      "      -------------------------------------- 0.2/12.8 MB 565.6 kB/s eta 0:00:23\n",
      "      -------------------------------------- 0.3/12.8 MB 737.3 kB/s eta 0:00:17\n",
      "     - ------------------------------------- 0.3/12.8 MB 807.1 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.4/12.8 MB 917.0 kB/s eta 0:00:14\n",
      "     - ------------------------------------- 0.5/12.8 MB 950.1 kB/s eta 0:00:13\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.0 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.6/12.8 MB 1.0 MB/s eta 0:00:12\n",
      "     -- ------------------------------------- 0.7/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.8/12.8 MB 1.1 MB/s eta 0:00:11\n",
      "     -- ------------------------------------- 0.9/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.0/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 1.1/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     --- ------------------------------------ 1.2/12.8 MB 1.3 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 1.4 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.7/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 1.5 MB/s eta 0:00:08\n",
      "     ------ --------------------------------- 2.0/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.1/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.2/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.3/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.4/12.8 MB 1.6 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.5/12.8 MB 1.7 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 2.7/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     -------- ------------------------------- 2.8/12.8 MB 1.7 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.0/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     --------- ------------------------------ 3.2/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 1.8 MB/s eta 0:00:06\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.9 MB/s eta 0:00:05\n",
      "     ------------ --------------------------- 4.1/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.2/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     ------------- -------------------------- 4.3/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.5/12.8 MB 2.0 MB/s eta 0:00:05\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 4.8/12.8 MB 2.1 MB/s eta 0:00:04\n",
      "     --------------- ------------------------ 5.1/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 5.8/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.1/12.8 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 6.2/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.3/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.5/12.8 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.8/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 6.9/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.3 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.7/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.4 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 8.1/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.3/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.8/12.8 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------------------- -------- 10.0/12.8 MB 2.5 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.3/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "576215a4-d3c1-47ab-be9d-fa7951f47e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383bf209-7111-4f27-ace1-d3cd7513dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return [token.text for token in nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bce173a-c06c-4f38-8bc7-a733b4b09245",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['cleaned_comment'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bcafb79-2b59-4c44-93f2-4e8048d397e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anvim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n",
      "                                             Comment Emotion  \\\n",
      "0  i seriously hate one subject to death but now ...    fear   \n",
      "1                 im so full of life i feel appalled   anger   \n",
      "2  i sit here to write i start to dig out my feel...    fear   \n",
      "3  ive been really angry with r and i feel like a...     joy   \n",
      "4  i feel suspicious if there is no one outside l...    fear   \n",
      "\n",
      "                                     cleaned_comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                 tokens_no_stopwords  \n",
      "0  [seriously, hate, one, subject, death, feel, r...  \n",
      "1                       [full, life, feel, appalled]  \n",
      "2  [sit, write, start, dig, feelings, think, afra...  \n",
      "3  [really, angry, r, feel, like, idiot, trusting...  \n",
      "4  [feel, suspicious, one, outside, like, rapture...  \n",
      "Processed data saved to: C:\\Users\\anvim\\Desktop\\PYTHON ASS\\machine learning\\nlp_dataset_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Remove common stopwords from tokenized text.\n",
    "    \"\"\"\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Apply stopword removal\n",
    "data['tokens_no_stopwords'] = data['tokens'].apply(remove_stopwords)\n",
    "\n",
    "# Display the preprocessed data\n",
    "print(\"Preprocessed Data:\")\n",
    "print(data[['Comment', 'Emotion', 'cleaned_comment', 'tokens_no_stopwords']].head())\n",
    "\n",
    "# Save the processed data to a new file if needed\n",
    "processed_file_path = r\"C:\\Users\\anvim\\Desktop\\PYTHON ASS\\machine learning\\nlp_dataset_processed.csv\"\n",
    "data.to_csv(processed_file_path, index=False)\n",
    "print(f\"Processed data saved to: {processed_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbaef7b5-80ab-48c9-96c9-e6a375e82196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix:\n",
      "        and    coding       fun        is      love    python\n",
      "0  0.000000  0.613356  0.000000  0.000000  0.789807  0.000000\n",
      "1  0.000000  0.385372  0.652491  0.652491  0.000000  0.000000\n",
      "2  0.584483  0.345205  0.000000  0.000000  0.444514  0.584483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "corpus = [\n",
    "    \"I love coding.\",\n",
    "    \"Coding is fun.\",\n",
    "    \"I love Python and coding.\"\n",
    "]\n",
    "\n",
    "# Choose the vectorizer: CountVectorizer or TfidfVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert to a DataFrame for better readability\n",
    "import pandas as pd\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_features = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# Display the feature matrix\n",
    "print(\"Feature Matrix:\")\n",
    "print(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e28a862c-805b-4f04-9769-c2552dcc38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load your dataset\n",
    "# Ensure the dataset has columns 'cleaned_comment' and 'emotion'\n",
    "# data = pd.read_csv(\"path_to_your_dataset.csv\")\n",
    "\n",
    "# Convert text to numerical features using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['cleaned_comment'])  # Feature matrix\n",
    "y = data['Emotion']  # Target labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "200f18f1-4f82-47d2-8430-7af7ebb2667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "Accuracy: 0.9006734006734006\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.94      0.90       392\n",
      "        fear       0.92      0.89      0.90       416\n",
      "         joy       0.91      0.88      0.90       380\n",
      "\n",
      "    accuracy                           0.90      1188\n",
      "   macro avg       0.90      0.90      0.90      1188\n",
      "weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train the model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f75526-514d-4f78-9869-6bcca92db950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy: 0.936026936026936\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.91      0.94      0.92       392\n",
      "        fear       0.97      0.91      0.94       416\n",
      "         joy       0.93      0.96      0.94       380\n",
      "\n",
      "    accuracy                           0.94      1188\n",
      "   macro avg       0.94      0.94      0.94      1188\n",
      "weighted avg       0.94      0.94      0.94      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027be093-de1f-45e8-bb2d-6998ba43a11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
